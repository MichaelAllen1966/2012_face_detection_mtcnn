{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection with a Multi-Task Cascaded Convolutional Neural Network (MT-CNN)\n",
    "\n",
    "Face detection is a 'non-trivial problem'.\n",
    "\n",
    "Here we apply a method called Multi-Task Cascaded Convolutional Neural Network (MT-CNN), using an implementation that uses tensorflow.\n",
    "\n",
    "If you are not using the enviroment provided with this project the following need to be installed:\n",
    "\n",
    "* matplotlib (conda or pip install)\n",
    "* mtcnn (pip install)\n",
    "* tensorflow conda or pip install)\n",
    "\n",
    "### Cascaded Convolutional Neural Network method\n",
    "\n",
    "State-of-the art results are achieved using a 'cascaded convultional neural network', which has pre-processing followed by three phases:\n",
    "\n",
    "1. Pre-processing - create images of varying scale\n",
    "1. Produce candidate windows using a shallow CNN (Proposal network, P-Net). Merge highly overlapping boxes.\n",
    "1. Filter out and refine windows using a more complex CNN (Refinement network, R-Net). Merge highly overlapping boxes.\n",
    "1. Use more complex CNN to refine and add facial features (Output network, O-Net). Adds points for eyes, end of nose, and edges of mouth.\n",
    "\n",
    "![](images/cascade.png)\n",
    "\n",
    "\n",
    "### Cascaded Convolutional Neural Architecture\n",
    "\n",
    "The achictecture is shown below.\n",
    "\n",
    "![](images/architecture.png)\n",
    "\n",
    "### Implementation\n",
    "\n",
    "Multi-task Cascaded Convolutional Neural Networks for Face Detection, based on TensorFlow\n",
    "\n",
    "https://pypi.org/project/mtcnn/\n",
    "\n",
    "### References\n",
    "\n",
    "Zhang, K., Zhang, Z., Li, Z., and Qiao, Y. (2016). Joint face detection and alignment using multitask cascaded convolutional networks. IEEE Signal Processing Letters, 23(10):1499â€“1503. https://ieeexplore.ieee.org/document/7553523\n",
    "\n",
    "Kaipeng Zhang, Zhanpeng Zhang, Zhifeng Li, Yu Qiao (2016) Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks. arXiv:1604.0287 https://arxiv.org/abs/1604.02878\n",
    "\n",
    "https://machinelearningmastery.com/how-to-perform-face-detection-with-classical-and-deep-learning-methods-in-python-with-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "from matplotlib.patches import Rectangle\n",
    "from mtcnn.mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1\n",
    "\n",
    "![](./images/test_1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting box boundaries and feature points\n",
    "\n",
    "Output is a list of dictionaries for boundary of face and location of key facial features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face detection with mtcnn on a photograph\n",
    "\n",
    "# load image from file\n",
    "filename = 'images/test_1.jpg'\n",
    "pixels = plt.imread(filename)\n",
    "\n",
    "# create the detector, using default weights\n",
    "detector = MTCNN()\n",
    "\n",
    "# detect faces in the image\n",
    "faces = detector.detect_faces(pixels)\n",
    "for face in faces:\n",
    "    print('\\n')\n",
    "    print(face)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using box boundaries to highlight faces using MatPlotLib\n",
    "\n",
    "We will use the output (list of dictionaries) to draw rectangles outlining faces over the photo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw an image with detected objects\n",
    "def draw_image_with_boxes(filename, result_list):\n",
    "    # load the image\n",
    "    data = plt.imread(filename)\n",
    "    # plot the image\n",
    "    plt.imshow(data)\n",
    "    # get the context for drawing boxes\n",
    "    ax = plt.gca()\n",
    "    # plot each box\n",
    "    for result in result_list:\n",
    "        # get coordinates\n",
    "        x, y, width, height = result['box']\n",
    "        # create the shape\n",
    "        rect = Rectangle((x, y), width, height, fill=False, color='red')\n",
    "        # draw the box\n",
    "        ax.add_patch(rect)\n",
    "    # show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'images/test_1.jpg'\n",
    "# load image from file\n",
    "pixels = plt.imread(filename)\n",
    "# create the detector, using default weights\n",
    "detector = MTCNN()\n",
    "# detect faces in the image\n",
    "faces = detector.detect_faces(pixels)\n",
    "# display faces on the original image\n",
    "draw_image_with_boxes(filename, faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2 - a more challenging example\n",
    "\n",
    "![](./images/test_2.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'images/test_2.jpg'\n",
    "# load image from file\n",
    "pixels = plt.imread(filename)\n",
    "# create the detector, using default weights\n",
    "detector = MTCNN()\n",
    "# detect faces in the image\n",
    "faces = detector.detect_faces(pixels)\n",
    "draw_image_with_boxes(filename, faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding feature points to the matplotlib output\n",
    "\n",
    "Eyes, end of nose, and ends of mouth will be highlighted (again using the dictionary output from mtcnn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw an image with detected objects\n",
    "def draw_image_with_boxes_and_features(filename, result_list):\n",
    "    # load the image\n",
    "    data = plt.imread(filename)\n",
    "    # plot the image\n",
    "    plt.imshow(data)\n",
    "    # get the context for drawing boxes\n",
    "    ax = plt.gca()\n",
    "    # plot each box\n",
    "    for result in result_list:\n",
    "        # get coordinates\n",
    "        x, y, width, height = result['box']\n",
    "        # create the shape\n",
    "        rect = Rectangle((x, y), width, height, fill=False, color='red')\n",
    "        # draw the box\n",
    "        ax.add_patch(rect)\n",
    "        # draw the dots\n",
    "        for key, value in result['keypoints'].items():\n",
    "            # create and draw dot\n",
    "            dot = Circle(value, radius=2, color='red')\n",
    "            ax.add_patch(dot)\n",
    "    # show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './images/thomas.jpg'\n",
    "# load image from file\n",
    "pixels = plt.imread(filename)\n",
    "# create the detector, using default weights\n",
    "detector = MTCNN()\n",
    "# detect faces in the image\n",
    "faces = detector.detect_faces(pixels)\n",
    "# display faces on the original image\n",
    "draw_image_with_boxes_and_features(filename, faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract faces as separate figures\n",
    "\n",
    "Let's extract and pront faces from the following picture example.\n",
    "\n",
    "![](./images/test_3.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw each face separately\n",
    "def draw_faces(filename, result_list):\n",
    "    # load plt image\n",
    "    data = plt.imread(filename)\n",
    "    # plot each face as a subplot\n",
    "    for i in range(len(result_list)):\n",
    "        # get coordinates\n",
    "        x1, y1, width, height = result_list[i]['box']\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        # define subplot\n",
    "        plt.subplot(1, len(result_list), i+1)\n",
    "        plt.axis('off')\n",
    "        # plot face\n",
    "        plt.imshow(data[y1:y2, x1:x2])\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "\n",
    "filename = './images/test_3.jpg'\n",
    "# load image from file\n",
    "pixels = plt.imread(filename)\n",
    "# create the detector, using default weights\n",
    "detector = MTCNN()\n",
    "# detect faces in the image\n",
    "faces = detector.detect_faces(pixels)\n",
    "# display faces on the original image\n",
    "draw_faces(filename, faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm. We seem to have some non-faces!\n",
    "\n",
    "(Though I did find that these disappeared if I reduced the size of the original picture to 50% of original height and width).\n",
    "\n",
    "Let's look at confidence values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image from file\n",
    "filename = './images/test_3.jpg'\n",
    "pixels = plt.imread(filename)\n",
    "# create the detector, using default weights\n",
    "detector = MTCNN()\n",
    "# detect faces in the image\n",
    "faces = detector.detect_faces(pixels)\n",
    "for face in faces:\n",
    "    print(face)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set required confidence level and save face extracts\n",
    "\n",
    "We'll set a higher confidence level to show faces (we could also change colour of box dependening on confidence level), and also sace the extracted faces as separate jpg files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_cutoff = 0.99\n",
    "\n",
    "# draw each face separately\n",
    "def draw_faces(filename, result_list):\n",
    "    counter = 1\n",
    "    # load the image\n",
    "    data = plt.imread(filename)\n",
    "    # plot each face as a subplot\n",
    "    for i in range(len(result_list)):\n",
    "        if result_list[i]['confidence'] >= confidence_cutoff:\n",
    "            # get coordinates\n",
    "            x1, y1, width, height = result_list[i]['box']\n",
    "            x2, y2 = x1 + width, y1 + height\n",
    "            # define subplot\n",
    "            plt.subplot(1, len(result_list), i+1)\n",
    "            plt.axis('off')\n",
    "            # plot face\n",
    "            face_extract = data[y1:y2, x1:x2]\n",
    "            plt.imshow(face_extract)   \n",
    "            plt.savefig(f'./saved_images/face_extract_{counter}.jpg')\n",
    "            counter += 1\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "\n",
    "filename = './images/test_3.jpg'\n",
    "# load image from file\n",
    "pixels = plt.imread(filename)\n",
    "# create the detector, using default weights\n",
    "detector = MTCNN()\n",
    "# detect faces in the image\n",
    "faces = detector.detect_faces(pixels)\n",
    "# display faces on the original image\n",
    "draw_faces(filename, faces)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
